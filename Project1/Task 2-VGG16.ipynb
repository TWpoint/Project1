{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2dfcac-3e77-4386-a09f-a6ca8f77350c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 2: Understand body language by gesture recognition with convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b2526-0909-476e-82ca-f688785da04d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Do literature search on Convolution Neural Network. Learn how to build a convolutional layer in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc76db6-4a78-42d2-b6e7-8835a48df88c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Referring to the guide in Task 1, build your own network for gesture classification using convolutional layers. Please see the references 4 in the manual to learn how to build convolutional layers in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b39684-c416-4dcc-b380-27d86876dbea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Analyse and comment on the performance of the model. Make a comparison between the fully connected based and convolutional based models and comment on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import torch.utils.data as utils_data\n",
    "import torch.nn as nn\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = './dataset/images'\n",
    "\n",
    "label_path = './dataset/labels'\n",
    "if not os.path.exists(label_path):\n",
    "    os.makedirs(label_path)\n",
    "\n",
    "files = os.listdir(path)\n",
    "index = 0\n",
    "for i, file in enumerate(files):\n",
    "    if file != '.DS_Store':\n",
    "        subclass_label_path = os.path.join(label_path, file + '.txt')\n",
    "        with open(subclass_label_path, 'w') as f:\n",
    "            f.write('#label\\n')\n",
    "        for _ in range(len(os.listdir(os.path.join(path, file)))):\n",
    "            with open(subclass_label_path, 'a') as f:\n",
    "                f.write('{:d}\\n'.format(index))\n",
    "        index = index + 1\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "Image = []\n",
    "path_images = './dataset/images'\n",
    "for mainDir, subDir, fileList in os.walk(path_images):\n",
    "    for file in fileList:\n",
    "        if file != '.DS_Store':\n",
    "            currentPath = os.path.join(mainDir, file)\n",
    "            Image.append(cv2.resize(cv2.imread(currentPath), (224, 224)))\n",
    "Image = np.array(Image)\n",
    "Image = np.transpose(Image, (0, 3, 1, 2))\n",
    "dataset_size, C, H, W = Image.shape\n",
    "\n",
    "Label = []\n",
    "path_labels = './dataset/labels'\n",
    "for file in os.listdir(path_labels):\n",
    "    Label.append(np.loadtxt(os.path.join(path_labels, file)))\n",
    "Label = np.array(list(itertools.chain.from_iterable(Label)))\n",
    "num_classes = int(np.max(Label)) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),  #input: 224*224*3\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())  # output: 224*224*64\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),  #input: 224*224*64\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))  # output: 224*224*64\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  #input: 224*224*64\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU())  # output: 112*112*128\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),  # input: 112*112*128\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))  # output: 112*112*128\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  # input: 112*112*128\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())  # output: 56*56*256\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),  # input: 56*56*256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU())  # output: 56*56*256\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),  # input: 56*56*256\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))  # output: 56*56*256\n",
    "        self.layer8 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),  # input: 56*56*256\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())  # output: 28*28*512\n",
    "        self.layer9 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),  # input: 28*28*512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())  # output: 28*28*512\n",
    "        self.layer10 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),  # input: 28*28*512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))  # output: 28*28*512\n",
    "        self.layer11 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),  # input: 28*28*512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())  #output: 14*14*512\n",
    "        self.layer12 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),  # input: 14*14*512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU())  #output: 14*14*512\n",
    "        self.layer13 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),  # input: 14*14*512\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))  #output: 7*7*512\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),  #input: 7*7*512\n",
    "            nn.Linear(7 * 7 * 512, 4096),\n",
    "            nn.ReLU())  #output: 1*1*4096\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # input: 1*1*4096\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())  #output: 1*1*4096\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))  #input: 1*1*4096 output: 1*1*4\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        out = self.layer9(out)\n",
    "        out = self.layer10(out)\n",
    "        out = self.layer11(out)\n",
    "        out = self.layer12(out)\n",
    "        out = self.layer13(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encapsulate data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "dataset = utils_data.TensorDataset(torch.Tensor(Image), torch.LongTensor(Label))\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_set, test_set = utils_data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = utils_data.DataLoader(dataset=train_set, batch_size=8, shuffle=True)\n",
    "test_loader = utils_data.DataLoader(dataset=test_set, batch_size=8, shuffle=True)\n",
    "\n",
    "print('Data is ready!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\ttrain loss=20.668015\ttrain accuracy=0.210\ttest accuracy=0.500\n",
      "epoch=1\ttrain loss=1.923880\ttrain accuracy=0.387\ttest accuracy=0.625\n",
      "epoch=2\ttrain loss=2.036543\ttrain accuracy=0.323\ttest accuracy=0.938\n",
      "epoch=3\ttrain loss=0.945616\ttrain accuracy=0.645\ttest accuracy=0.938\n",
      "epoch=4\ttrain loss=1.865938\ttrain accuracy=0.468\ttest accuracy=0.500\n",
      "epoch=5\ttrain loss=0.947484\ttrain accuracy=0.548\ttest accuracy=0.938\n",
      "epoch=6\ttrain loss=0.926650\ttrain accuracy=0.613\ttest accuracy=0.625\n",
      "epoch=7\ttrain loss=1.030805\ttrain accuracy=0.565\ttest accuracy=0.500\n",
      "epoch=8\ttrain loss=0.837630\ttrain accuracy=0.694\ttest accuracy=0.562\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m batch_loss \u001B[38;5;241m=\u001B[39m loss_func(batch_output, batch_label)\n\u001B[1;32m     12\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m \u001B[43mbatch_loss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     16\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m batch_loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/.conda/envs/Project1/lib/python3.10/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/Project1/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for epoch in range(500):\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, (batch_image, batch_label) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        # if torch.cuda.is_available():\n",
    "        #     batch_image, batch_label = batch_image.cuda(), batch_label.cuda()\n",
    "        batch_output = model(batch_image)\n",
    "        batch_loss = loss_func(batch_output, batch_label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += batch_loss.item()\n",
    "\n",
    "        # train accuracy\n",
    "        _, train_predicted = torch.max(batch_output.data, 1)\n",
    "        train_acc += (train_predicted == batch_label).sum().item()\n",
    "\n",
    "    train_acc /= train_size\n",
    "    running_loss /= (step + 1)\n",
    "\n",
    "    # ----------test----------\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for test_image, test_label in test_loader:\n",
    "        test_output = model(test_image)\n",
    "        _, predicted = torch.max(test_output.data, 1)\n",
    "        test_acc += (predicted == test_label).sum().item()\n",
    "    test_acc /= test_size\n",
    "\n",
    "    print('epoch={:d}\\ttrain loss={:.6f}\\ttrain accuracy={:.3f}\\ttest accuracy={:.3f}'.format(\n",
    "        epoch, running_loss, train_acc, test_acc))\n",
    "\n",
    "    if test_acc >= best_accuracy:\n",
    "        torch.save(model.state_dict(), './trained_models/CNN_model_VGG16.pkl')\n",
    "        best_accuracy = test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}