{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f2dfcac-3e77-4386-a09f-a6ca8f77350c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Task 2: Understand body language by gesture recognition with convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b2526-0909-476e-82ca-f688785da04d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Do literature search on Convolution Neural Network. Learn how to build a convolutional layer in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc76db6-4a78-42d2-b6e7-8835a48df88c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Referring to the guide in Task 1, build your own network for gesture classification using convolutional layers. Please see the references 4 in the manual to learn how to build convolutional layers in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b39684-c416-4dcc-b380-27d86876dbea",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Analyse and comment on the performance of the model. Make a comparison between the fully connected based and convolutional based models and comment on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import torch.utils.data as utils_data\n",
    "import torch.nn as nn\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = './dataset/images'\n",
    "\n",
    "label_path = './dataset/labels'\n",
    "if not os.path.exists(label_path):\n",
    "    os.makedirs(label_path)\n",
    "\n",
    "files = os.listdir(path)\n",
    "index = 0\n",
    "for i, file in enumerate(files):\n",
    "    if file != '.DS_Store':\n",
    "        subclass_label_path = os.path.join(label_path, file + '.txt')\n",
    "        with open(subclass_label_path, 'w') as f:\n",
    "            f.write('#label\\n')\n",
    "        for _ in range(len(os.listdir(os.path.join(path, file)))):\n",
    "            with open(subclass_label_path, 'a') as f:\n",
    "                f.write('{:d}\\n'.format(index))\n",
    "        index = index + 1\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "Image = []\n",
    "path_images = './dataset/images'\n",
    "for mainDir, subDir, fileList in os.walk(path_images):\n",
    "    for file in fileList:\n",
    "        if file != '.DS_Store':\n",
    "            currentPath = os.path.join(mainDir, file)\n",
    "            Image.append(cv2.resize(cv2.imread(currentPath), (32, 32)))\n",
    "Image = np.array(Image)\n",
    "Image = np.transpose(Image, (0, 3, 1, 2))\n",
    "dataset_size, C, H, W = Image.shape\n",
    "\n",
    "Label = []\n",
    "path_labels = './dataset/labels'\n",
    "for file in os.listdir(path_labels):\n",
    "    Label.append(np.loadtxt(os.path.join(path_labels, file)))\n",
    "Label = np.array(list(itertools.chain.from_iterable(Label)))\n",
    "num_classes = int(np.max(Label)) + 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.module1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*32,256),\n",
    "            nn.Linear(256,64),\n",
    "            nn.Linear(64,4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.module1(x)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = CNNModel()\n",
    "# if torch.cuda.is_available():\n",
    "#     model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Encapsulate data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is ready!\n"
     ]
    }
   ],
   "source": [
    "dataset = utils_data.TensorDataset(torch.Tensor(Image), torch.LongTensor(Label))\n",
    "split_ratio = 0.8\n",
    "train_size = int(split_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "train_set, test_set = utils_data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = utils_data.DataLoader(dataset=train_set, batch_size=8, shuffle=True)\n",
    "test_loader = utils_data.DataLoader(dataset=test_set, batch_size=8, shuffle=True)\n",
    "\n",
    "print('Data is ready!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0\ttrain loss=20.917231\ttrain accuracy=0.403\ttest accuracy=0.500\n",
      "epoch=1\ttrain loss=1.337465\ttrain accuracy=0.726\ttest accuracy=0.938\n",
      "epoch=2\ttrain loss=0.651810\ttrain accuracy=0.806\ttest accuracy=1.000\n",
      "epoch=3\ttrain loss=0.537334\ttrain accuracy=0.903\ttest accuracy=1.000\n",
      "epoch=4\ttrain loss=0.093872\ttrain accuracy=0.968\ttest accuracy=1.000\n",
      "epoch=5\ttrain loss=0.058360\ttrain accuracy=0.968\ttest accuracy=1.000\n",
      "epoch=6\ttrain loss=0.000007\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=7\ttrain loss=0.000439\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=8\ttrain loss=0.000255\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=9\ttrain loss=0.000078\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=10\ttrain loss=0.000021\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=11\ttrain loss=0.000011\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=12\ttrain loss=0.000009\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=13\ttrain loss=0.000008\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=14\ttrain loss=0.000007\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=15\ttrain loss=0.000008\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=16\ttrain loss=0.000006\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=17\ttrain loss=0.000005\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=18\ttrain loss=0.000005\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=19\ttrain loss=0.000005\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=20\ttrain loss=0.000005\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=21\ttrain loss=0.000004\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=22\ttrain loss=0.000004\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=23\ttrain loss=0.000004\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=24\ttrain loss=0.000004\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=25\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=26\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=27\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=28\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=29\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=30\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=31\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=32\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=33\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=34\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=35\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=36\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=37\ttrain loss=0.000003\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=38\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=39\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=40\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=41\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=42\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=43\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=44\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=45\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=46\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=47\ttrain loss=0.000002\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=48\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=49\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=50\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=51\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=52\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=53\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=54\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=55\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=56\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=57\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=58\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=59\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=60\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=61\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=62\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=63\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=64\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=65\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=66\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=67\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=68\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=69\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=70\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=71\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=72\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=73\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=74\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=75\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=76\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=77\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=78\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=79\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=80\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=81\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=82\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=83\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=84\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=85\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=86\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=87\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=88\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=89\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=90\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=91\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=92\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=93\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=94\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=95\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=96\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=97\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=98\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=99\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=100\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=101\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=102\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=103\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=104\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=105\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=106\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=107\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=108\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=109\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=110\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=111\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=112\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=113\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=114\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=115\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=116\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=117\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=118\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=119\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=120\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=121\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=122\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=123\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=124\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=125\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=126\ttrain loss=0.000001\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=127\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=128\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=129\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=130\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=131\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=132\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=133\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=134\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=135\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=136\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=137\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=138\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=139\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=140\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=141\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=142\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=143\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=144\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=145\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=146\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=147\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=148\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=149\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=150\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=151\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=152\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=153\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=154\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=155\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=156\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=157\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=158\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=159\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=160\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=161\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=162\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=163\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=164\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=165\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=166\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=167\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=168\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=169\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n",
      "epoch=170\ttrain loss=0.000000\ttrain accuracy=1.000\ttest accuracy=1.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_28032\\1547575682.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m         \u001B[1;31m# if torch.cuda.is_available():\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[1;31m#     batch_image, batch_label = batch_image.cuda(), batch_label.cuda()\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m         \u001B[0mbatch_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_image\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m         \u001B[0mbatch_loss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mloss_func\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch_output\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_label\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\chen qing hua\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_28032\\2732528106.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m         \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodule1\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0moutput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\chen qing hua\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\chen qing hua\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    137\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    138\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 139\u001B[1;33m             \u001B[0minput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    140\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\chen qing hua\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1128\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1131\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1132\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\chen qing hua\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    455\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 457\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    458\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    459\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\chen qing hua\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    452\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[0;32m    453\u001B[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[1;32m--> 454\u001B[1;33m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[0;32m    455\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    456\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for epoch in range(500):\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for step, (batch_image, batch_label) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        # if torch.cuda.is_available():\n",
    "        #     batch_image, batch_label = batch_image.cuda(), batch_label.cuda()\n",
    "        batch_output = model(batch_image)\n",
    "        batch_loss = loss_func(batch_output, batch_label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += batch_loss.item()\n",
    "\n",
    "        # train accuracy\n",
    "        _, train_predicted = torch.max(batch_output.data, 1)\n",
    "        train_acc += (train_predicted == batch_label).sum().item()\n",
    "\n",
    "    train_acc /= train_size\n",
    "    running_loss /= (step + 1)\n",
    "\n",
    "    # ----------test----------\n",
    "    model.eval()\n",
    "    test_acc = 0.0\n",
    "    for test_image, test_label in test_loader:\n",
    "        test_output = model(test_image)\n",
    "        _, predicted = torch.max(test_output.data, 1)\n",
    "        test_acc += (predicted == test_label).sum().item()\n",
    "    test_acc /= test_size\n",
    "\n",
    "    print('epoch={:d}\\ttrain loss={:.6f}\\ttrain accuracy={:.3f}\\ttest accuracy={:.3f}'.format(\n",
    "        epoch, running_loss, train_acc, test_acc))\n",
    "\n",
    "    if test_acc >= best_accuracy:\n",
    "        torch.save(model.state_dict(), './trained_models/CNN_model.pkl')\n",
    "        best_accuracy = test_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}